Metric Server is one of the most fundamental tools that every Kubernetes engineer should know. These resources aim to feed Horizontal Pod Autoscaler and Vertical Pod Autoscaler to make decisions on scaling by pulling in your Node and Pod level Metrics. ðŸš€



ð—ªð—µð—®ð˜ ð—±ð—¼ð—²ð˜€ ð—¶ð˜ ð—±ð—¼?



â†’ Pulls real-time data on CPU usage



â†’ Tracks memory consumption



â†’ Collects network statistics



â†’ Aggregates all metrics



â†’ Stores everything in memory





ð—›ð—¼ð˜„ ð—±ð—¼ð—²ð˜€ ð—¶ð˜ ð—®ð—°ð˜ð˜‚ð—®ð—¹ð—¹ð˜† ð˜„ð—¼ð—¿ð—¸? ðŸ”



Kubernetes uses kubelet (an agent running on each node) which includes cAdvisor (Container Advisor).



cAdvisor â†’ retrieves metrics from pods and nodes â†’ exposes them through kubelet API â†’ Metric Server collects this data





ð—§ð—µð—² ð—¯ð—²ð˜€ð˜ ð—½ð—®ð—¿ð˜? ð—¢ð—»ð—°ð—² ð—±ð—²ð—½ð—¹ð—¼ð˜†ð—²ð—±, ð˜†ð—¼ð˜‚ ð—°ð—®ð—» ð—²ð—®ð˜€ð—¶ð—¹ð˜† ð—°ð—µð—²ð—°ð—¸ ð—ºð—²ð˜ð—¿ð—¶ð—°ð˜€ ð˜„ð—¶ð˜ð—µ ð˜€ð—¶ð—ºð—½ð—¹ð—² ð—°ð—¼ð—ºð—ºð—®ð—»ð—±ð˜€:



ð—¸ð˜‚ð—¯ð—²ð—°ð˜ð—¹ ð˜ð—¼ð—½ ð—»ð—¼ð—±ð—²: See node-level resource usage 



ð—¸ð˜‚ð—¯ð—²ð—°ð˜ð—¹ ð˜ð—¼ð—½ ð—½ð—¼ð—±: Monitor pod-level consumption



No complex setup. No heavy overhead. Just the essential metrics you need to keep your Kubernetes environment running and scaling smoothly. ðŸ’¯





ð—¡ð—¼ð˜ð—² âš ï¸ : Metrics Server is meant only for autoscaling purposes. For example, don't use it to forward metrics to monitoring solutions, or as a source of monitoring solution metrics. In such cases please collect metrics from Kubelet /ð˜®ð˜¦ð˜µð˜³ð˜ªð˜¤ð˜´/ð˜³ð˜¦ð˜´ð˜°ð˜¶ð˜³ð˜¤ð˜¦ endpoint directly.
```mermaid
graph TD
    subgraph "Kubernetes Node"
        K[Kubelet] --> |Exposes metrics at /metrics| C[cAdvisor]
        C -->|Container metrics| K
    end
    
    K -->|Resource metrics| MS[Metrics Server]




```
